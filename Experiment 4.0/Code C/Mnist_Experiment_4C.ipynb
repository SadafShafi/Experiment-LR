{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mnist_Experiment_4C.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAsDjUXED-sP"
      },
      "source": [
        "# *LR decresing wrt epoch (inverse relationship) with random fluctutions *\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfFZwtotppg4"
      },
      "source": [
        "*Save and Load results from here*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfeQyoKhlJ_C"
      },
      "source": [
        "def record_Results(key,results):\n",
        "  import json\n",
        "  from google.colab import drive\n",
        "\n",
        "\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  dictionary ={\n",
        "      key : results\n",
        "  } \n",
        "  json_object = json.dumps(dictionary)\n",
        "\n",
        "  FILE_PATH = \"/content/drive/My Drive/Results/\"+\"Mnist_Experiment_4C\"+str(key)+\".json\"\n",
        "  f = open(FILE_PATH, \"w\")\n",
        "  f.write(json_object)\n",
        "  print(\"recorded\")\n",
        "\n",
        "def Get_Results(file):\n",
        "  import json\n",
        "  from google.colab import drive\n",
        "\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  FILE_PATH = \"/content/drive/My Drive/Results/\"+\"Mnist_Experiment_4C\"+str(file)+\".json\"\n",
        "  f = open(FILE_PATH, \"r\")\n",
        "  json_object = json.load(f)\n",
        "  \n",
        "  return json_object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAve6DCL4JH4"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiEBhQSxHwWA"
      },
      "source": [
        "**Starting GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SUjTleWIogY",
        "outputId": "a18c52c2-a549-46ad-a9a5-902f30117607"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Azwjhr5ZIpqD",
        "outputId": "11f05dec-df27-49e0-b2d5-dc00cb3c41e1"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "2.9252137599999912\n",
            "GPU (s):\n",
            "0.04432145000001242\n",
            "GPU speedup over CPU: 65x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWoEqyMuXFF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4752d181-78ae-42ab-ad7b-a8c1bbc26c02"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "sh = train_images.shape\n",
        "sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLSTQg4RbemP"
      },
      "source": [
        "def simple_model():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45M1nSqEFW3_"
      },
      "source": [
        "def Plotter(acc,val_acc,loss,val_loss,l_r):\n",
        "  \n",
        "  plt.plot(acc, label='accuracy')\n",
        "  plt.plot(val_acc, label = 'val_accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  plt.plot(loss, label='loss')\n",
        "  plt.plot(val_loss, label = 'val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(l_r, label='Learning Rate')\n",
        "  # plt.plot(val_loss, label = 'val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('LR')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf4G6RHVEqUu"
      },
      "source": [
        "model = simple_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Yu_m-TZUWGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5af97d9d-32c9-4d7a-cb49-1b7c2982de47"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-JI73CgFFOa"
      },
      "source": [
        "**Normal default fit** : LR and Batch Size default"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5qbc-A1ihfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10082713-0f92-4cc1-9a5b-d523a48739be"
      },
      "source": [
        "history = model.fit(train_images, train_labels, epochs=100, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4307 - accuracy: 0.8762 - val_loss: 0.1431 - val_accuracy: 0.9565\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1262 - accuracy: 0.9630 - val_loss: 0.1033 - val_accuracy: 0.9668\n",
            "Epoch 3/100\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.0809 - accuracy: 0.9756"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OtWvJwjIEdM"
      },
      "source": [
        "acc_1 = history.history['accuracy']\n",
        "val_acc_1 = history.history['val_accuracy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NetOPNdvur-t"
      },
      "source": [
        "#Save these values in your jsonm\n",
        "record_Results(\"acc_1\",acc_1)\n",
        "record_Results(\"val_acc_1\",val_acc_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nKamdPXux0d"
      },
      "source": [
        "#Get the saved results\n",
        "acc_1 = Get_Results(\"acc_1\")[\"acc_1\"]\n",
        "val_acc_1 = Get_Results(\"val_acc_1\")[\"val_acc_1\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtyDF0MKUcM7"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "# plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('loss')\n",
        "# plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxrhQRk5RkJ2"
      },
      "source": [
        "**Test for LR**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d_uY9su-Qzg"
      },
      "source": [
        "from random import random,randint,randrange,uniform\n",
        "lr = []\n",
        "epoo=100\n",
        "for z,batch_size in zip(range(1,epoo+1),range(5,10000,5)):\n",
        "\n",
        "  # print(z,(batch_size)/((z+1)**(3/2))/80)\n",
        "  \n",
        "\n",
        "\n",
        "  # if (z%2 == 0):\n",
        "  #   LR = random() * batch_size/10000\n",
        "  #   lr.append(LR)\n",
        "  # else:\n",
        "  LR = random() / (z*10000)\n",
        "  lr.append(LR)\n",
        "\n",
        "# lr = lr[::-1] \n",
        "lord_LR = lr\n",
        "# print(min(lr))\n",
        "\n",
        "\n",
        "plt.plot(lr, label='Learning Rate')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('LR')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# lr = []\n",
        "# epoo=150\n",
        "# for z,batch_size in zip(range(1,epoo+1),range(5,10000,5)):\n",
        "\n",
        "#   # print(z,(batch_size)/((z+1)**(3/2))/80)\n",
        "  \n",
        "\n",
        "#   LR = random() * z/10000\n",
        "#   # LR=LR/8\n",
        "#   lr.append(LR)\n",
        "\n",
        "# plt.plot(lr, label='Learning Rate')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('LR')\n",
        "# plt.legend(loc='lower right')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGg5WxHXhj5G"
      },
      "source": [
        "model = simple_model()\n",
        "\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "LR = 0.01\n",
        "epoch = 1\n",
        "batch_size = 100\n",
        "\n",
        "val_acc = []\n",
        "acc = []\n",
        "val_loss = []\n",
        "loss = []\n",
        "l_r = []\n",
        "\n",
        "num = 0\n",
        "\n",
        "x = 0\n",
        "# kr = lr\n",
        "for z,batch_size in zip(range(1,epoo),range(5,10000,5)):\n",
        "\n",
        "  # if (z%2 == 0):\n",
        "  #   LR = random() * batch_size/10000\n",
        "  # # lr.append(LR)\n",
        "  # else:\n",
        "  LR = random() / (z*10000)\n",
        "  # lr.append(LR)\n",
        "\n",
        "  print(\"\\n\\nepoch {z}, Learning Rate {LR}, Batch Size  {batch_size} \"\n",
        "                    .format(z=z,LR=LR,batch_size=batch_size))\n",
        "\n",
        "  def set_LR(epoch,lr):\n",
        "    global LR\n",
        "    global l_r\n",
        "    global x\n",
        "    global lord_LR \n",
        "\n",
        "    LR=lord_LR[x]\n",
        "    x+=1\n",
        "    if(LR>0.009):\n",
        "      LR = 0.009\n",
        "    l_r.append(LR)\n",
        "    return LR\n",
        "\n",
        "  call = [ LearningRateScheduler(set_LR,verbose=1) ]\n",
        "\n",
        "  history = model.fit(\n",
        "            train_images, train_labels, \n",
        "            validation_data=(test_images, test_labels),\n",
        "            epochs=epoch,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=call\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "  acc.append(history.history['accuracy'])\n",
        "  val_acc.append(history.history['val_accuracy'])\n",
        "  loss.append(history.history['loss'])\n",
        "  val_loss.append(history.history['val_loss'])\n",
        "\n",
        "  # if(num >= 50 ):\n",
        "  #   x = input(\"type anything if you want to continue >  \")\n",
        "  #   num = 0\n",
        "  # num += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "effElJP_KMDZ"
      },
      "source": [
        "acc_2 = acc\n",
        "val_acc_2 = val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcS18cPHpmYQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rbb_rp0pm2B"
      },
      "source": [
        "#Save these values in your jsonm\n",
        "record_Results(\"acc_1\",acc_1)\n",
        "record_Results(\"val_acc_1\",val_acc_1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO9VwJcHpm2C"
      },
      "source": [
        "#Get the saved results\n",
        "acc_1 = Get_Results(\"acc_1\")[\"acc_1\"]\n",
        "val_acc_1 = Get_Results(\"val_acc_1\")[\"val_acc_1\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46nEyb5Ohtsc"
      },
      "source": [
        "Plotter(acc,val_acc,loss,val_loss,l_r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnLBA5jb03yH"
      },
      "source": [
        "**Keeping batch size constant**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR2ixkydxmF_"
      },
      "source": [
        "initial_learning_rate = 0.009\n",
        "decay_steps=5\n",
        "decay_rate=0.5\n",
        "LR = []\n",
        "for i in range(51):\n",
        "  lr = initial_learning_rate * decay_rate **(i / decay_steps)\n",
        "  LR.append(lr)\n",
        "plt.plot(LR, label='LR')\n",
        "# plt.plot(history.history['val_loss'], label = 'val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('LR')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfKKgrkM0x0n"
      },
      "source": [
        "\n",
        "model = simple_model()\n",
        "\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "LR = 0.01\n",
        "# epoch = 1\n",
        "batch_size = 100\n",
        "\n",
        "val_acc = []\n",
        "acc = []\n",
        "val_loss = []\n",
        "loss = []\n",
        "l_r = []\n",
        "for z,batch_size in zip(range(1,epoo+1),range(5,10000,5)):\n",
        "\n",
        "  LR = (batch_size)/(((z+1)**(3/2))*80)\n",
        "  LR=LR/8\n",
        "\n",
        "  print(\"\\n\\nepoch {z}, Learning Rate {LR}, Batch Size  {batch_size} \"\n",
        "                    .format(z=z,LR=LR,batch_size=batch_size))\n",
        "\n",
        "  def set_LR(epoch,lr):\n",
        "    global LR\n",
        "    global l_r\n",
        "    l_r.append(LR)\n",
        "    return LR\n",
        "\n",
        "  call = [ LearningRateScheduler(set_LR,verbose=1) ]\n",
        "\n",
        "  history = model.fit(\n",
        "            train_images, train_labels, \n",
        "            validation_data=(test_images, test_labels),\n",
        "            epochs=epoch,\n",
        "            # batch_size=batch_size,\n",
        "            callbacks=call\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "  acc.append(history.history['accuracy'])\n",
        "  val_acc.append(history.history['val_accuracy'])\n",
        "  loss.append(history.history['loss'])\n",
        "  val_loss.append(history.history['val_loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AR32PX4H5pJ"
      },
      "source": [
        "from time import sleep\n",
        "sleep(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCmIAb9SKQjl"
      },
      "source": [
        "acc_3 = acc\n",
        "val_acc_3 = val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLQWe3CTppO_"
      },
      "source": [
        "#Save these values in your jsonm\n",
        "record_Results(\"acc_3\",acc_3)\n",
        "record_Results(\"val_acc_3\",val_acc_3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQEN-DI4ppPB"
      },
      "source": [
        "#Get the saved results\n",
        "acc_3 = Get_Results(\"acc_3\")[\"acc_3\"]\n",
        "val_acc_3 = Get_Results(\"val_acc_3\")[\"val_acc_3\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMhOsVmX02Jn"
      },
      "source": [
        "Plotter(acc,val_acc,loss,val_loss,l_r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlJErWV1HG06"
      },
      "source": [
        "**LR constant**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSS4isyhHHK_"
      },
      "source": [
        "model = simple_model()\n",
        "\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "LR = 0.01\n",
        "epoch = 1\n",
        "batch_size = 100\n",
        "\n",
        "val_acc = []\n",
        "acc = []\n",
        "val_loss = []\n",
        "loss = []\n",
        "l_r = []\n",
        "for z,batch_size in zip(range(1,epoo+1),range(5,10000,5)):\n",
        "\n",
        "  LR = (batch_size)/(((z+1)**(3/2))*80)\n",
        "  LR=LR/8\n",
        "\n",
        "  print(\"\\n\\nepoch {z}, Learning Rate {LR}, Batch Size  {batch_size} \"\n",
        "                    .format(z=z,LR=LR,batch_size=batch_size))\n",
        "\n",
        "  def set_LR(epoch,lr):\n",
        "    global LR\n",
        "    global l_r\n",
        "    l_r.append(LR)\n",
        "    return LR\n",
        "\n",
        "  call = [ LearningRateScheduler(set_LR,verbose=1) ]\n",
        "\n",
        "  history = model.fit(\n",
        "            train_images, train_labels, \n",
        "            validation_data=(test_images, test_labels),\n",
        "            epochs=epoch,\n",
        "            batch_size=batch_size,\n",
        "            # callbacks=call\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "  acc.append(history.history['accuracy'])\n",
        "  val_acc.append(history.history['val_accuracy'])\n",
        "  loss.append(history.history['loss'])\n",
        "  val_loss.append(history.history['val_loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdT9imOdKWEY"
      },
      "source": [
        "acc_4 = acc\n",
        "val_acc_4 = val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg4bV-r7pr3P"
      },
      "source": [
        "#Save these values in your jsonm\n",
        "record_Results(\"acc_4\",acc_4)\n",
        "record_Results(\"val_acc_4\",val_acc_4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFDm1jk-pr3R"
      },
      "source": [
        "#Get the saved results\n",
        "acc_4 = Get_Results(\"acc_4\")[\"acc_4\"]\n",
        "val_acc_4 = Get_Results(\"val_acc_4\")[\"val_acc_4\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-0-Hlo-HSYO"
      },
      "source": [
        "Plotter(acc_4,val_acc_4,loss,val_loss,l_r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKu3S8KzKZ7i"
      },
      "source": [
        "**Plotting all of them**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI9csZnyKZOZ"
      },
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "plt.plot(acc_1, label='LR & BS = const acc',ls='-.',c='b')\n",
        "plt.plot(val_acc_1, label = 'LR & BS = const val_acc',c='b')\n",
        "plt.plot(acc_2, label='LR ∝ BS/epoch acc',ls='-.',c='r')\n",
        "plt.plot(val_acc_2, label = 'LR ∝ BS_/epoch val_acc',c='r')\n",
        "plt.plot(acc_3, label='BS = const acc',ls='-.',c='g')\n",
        "plt.plot(val_acc_3, label = 'BS = const val_acc',c='g')\n",
        "plt.plot(acc_4, label='LR = const acc',ls='-.',c='y')\n",
        "plt.plot(val_acc_4, label = 'LR = const val_acc',c='y')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj2c9YryLqpV"
      },
      "source": [
        "acc_1_dif = []\n",
        "for i in range(len(acc_1)): acc_1_dif.append(acc_1[i] - val_acc_1[i]) \n",
        "acc_2_dif = []\n",
        "for i in range(len(acc_2)): acc_2_dif.append(acc_2[i][0] - val_acc_2[i][0]) \n",
        "acc_3_dif = []\n",
        "for i in range(len(acc_3)): acc_3_dif.append(acc_3[i][0] - val_acc_3[i][0]) \n",
        "acc_4_dif = []\n",
        "for i in range(len(acc_4)): acc_4_dif.append(acc_4[i][0] - val_acc_4[i][0]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7qenWWVLOxl"
      },
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "plt.plot(acc_1_dif, label='LR & BS = const acc',ls='-.',c='b')\n",
        "# plt.plot(val_acc_1, label = 'LR & BS = const val_acc',c='b')\n",
        "plt.plot(acc_2_dif, label='LR ∝ BS/epoch acc',ls='-.',c='r')\n",
        "# plt.plot(val_acc_2, label = 'LR ∝ BS_/epoch val_acc',c='r')\n",
        "plt.plot(acc_3_dif, label='BS = const acc',ls='-.',c='g')\n",
        "# plt.plot(val_acc_3, label = 'BS = const val_acc',c='g')\n",
        "plt.plot(acc_4_dif, label='LR = const acc',ls='-.',c='y')\n",
        "# plt.plot(val_acc_4, label = 'LR = const val_acc',c='y')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofygs8rU2O0t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}